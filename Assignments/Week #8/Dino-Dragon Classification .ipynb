{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "726eb1cf",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a94b225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e9b90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41878238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dff3b10",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b830f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [......................................................................] 109298562 / 109298562"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dino-dragon.zip'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "wget.download(\"https://github.com/alexeygrigorev/dino-or-dragon/releases/download/data/dino-dragon.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b0e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(\"dino-dragon.zip\",\"r\") as zip_obj:\n",
    "    zip_obj.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c276331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6449fec1",
   "metadata": {},
   "source": [
    "The dataset contains around 1900 images of dinos and around 1900 images of dragons.\n",
    "\n",
    "The dataset contains separate folders for training and validation.\n",
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "717e87a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./train/\"\n",
    "validation_path = \"./test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5079b35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20d00290",
   "metadata": {},
   "source": [
    "For this homework we will use Convolutional Neural Network (CNN). Like in the lectures, we'll use Keras.\n",
    "\n",
    "You need to develop the model with following structure:\n",
    "\n",
    "    The shape for input should be (150, 150, 3)\n",
    "    Next, create a convolutional layer (Conv2D):\n",
    "        Use 32 filters\n",
    "        Kernel size should be (3, 3) (that's the size of the filter)\n",
    "        Use 'relu' as activation\n",
    "    Reduce the size of the feature map with max pooling (MaxPooling2D)\n",
    "        Set the pooling size to (2, 2)\n",
    "    Turn the multi-dimensional result into vectors using a Flatten layer\n",
    "    Next, add a Dense layer with 64 neurons and 'relu' activation\n",
    "    Finally, create the Dense layer with 1 neuron - this will be the output\n",
    "        The output layer should have an activation - use the appropriate activation for the binary classification case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7205ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba1b077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.activations import relu, sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30fb27f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "input_shape = (150, 150, 3)\n",
    "filters= 32\n",
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "conv2d_activation = relu\n",
    "dense_layer_activation = relu\n",
    "output_activation = sigmoid\n",
    "dense_layer_1_neurons = 64\n",
    "output_layer_neurons = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9645aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Definition\n",
    "model = Sequential([\n",
    "                    InputLayer(input_shape=input_shape),\n",
    "                    Conv2D(filters=filters, kernel_size=kernel_size, \n",
    "                           kernel_initializer='glorot_normal', activation=conv2d_activation),\n",
    "                    MaxPooling2D(pool_size=pool_size),\n",
    "                    Flatten(),\n",
    "                    Dense(units=dense_layer_1_neurons, activation=dense_layer_activation),\n",
    "                    Dense(units=output_layer_neurons, activation=output_activation)\n",
    "                  ])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94903b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c02a2e9e",
   "metadata": {},
   "source": [
    "As optimizer use SGD with the following parameters:\n",
    "\n",
    "    SGD(lr=0.002, momentum=0.8)\n",
    "\n",
    "For clarification about kernel size and max pooling, check Office Hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "099f2c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Model Optimizer\n",
    "from tensorflow.keras.optimizers import SGD  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "046b68dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer Parameters\n",
    "learning_rate = 0.002\n",
    "momentum = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6de32c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer Definition\n",
    "optimizer = SGD(learning_rate=learning_rate,\n",
    "                momentum=momentum, \n",
    "                name='SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1033da47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Definition\n",
    "loss = 'binary_crossentropy' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3ae6fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics definition\n",
    "metrics = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44225a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss, \n",
    "              metrics=metrics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e286988b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95fc8e53",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09da8f0",
   "metadata": {},
   "source": [
    "Since we have a binary classification problem, what is the best loss function for us?\n",
    "\n",
    "- **binary crossentropy**\n",
    "- focal loss\n",
    "- mean squared error\n",
    "- categorical crossentropy\n",
    "    \n",
    "Note: since we specify an activation for the output layer, we don't need to set from_logits=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c128a93d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea4a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3db713d3",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93cab15",
   "metadata": {},
   "source": [
    "What's the total number of parameters of the model? You can use the summary method for that.\n",
    "\n",
    "- 9215873\n",
    "- **11215873**\n",
    "- 14215873\n",
    "- 19215873"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee319dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680e4fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9e3b811",
   "metadata": {},
   "source": [
    "# Generators and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0865cc4",
   "metadata": {},
   "source": [
    "For the next two questions, use the following data generator for both train and validation:\n",
    "\n",
    "ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    We don't need to do any additional pre-processing for the images.\n",
    "    \n",
    "    When reading the data from train/val directories, check the class_mode parameter. Which value should it be for a binary classification problem?\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e19a83",
   "metadata": {},
   "source": [
    "***class_mode should be binary in this case***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add56db5",
   "metadata": {},
   "source": [
    "Use batch_size=20\n",
    "\n",
    "Use shuffle=True for both training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54d19f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f038608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size=(150, 150)\n",
    "color_mode=\"rgb\"\n",
    "class_mode='binary'\n",
    "batch_size=20\n",
    "shuffle=True \n",
    "seed=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e00c144a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(train_path,\n",
    "                                                                        target_size=target_size,\n",
    "                                                                        color_mode=color_mode,\n",
    "                                                                        classes=os.listdir(train_path),\n",
    "                                                                        class_mode=class_mode,\n",
    "                                                                        batch_size=batch_size,\n",
    "                                                                        shuffle=shuffle,\n",
    "                                                                        seed=seed\n",
    "                                                                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d534d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 394 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(validation_path,\n",
    "                                                                             target_size=target_size,\n",
    "                                                                             color_mode=color_mode,\n",
    "                                                                             classes=os.listdir(validation_path),\n",
    "                                                                             class_mode=class_mode,\n",
    "                                                                             batch_size=batch_size,\n",
    "                                                                             shuffle=shuffle,\n",
    "                                                                             seed=seed\n",
    "                                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4dc242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea2c0790",
   "metadata": {},
   "source": [
    "For training use .fit() with the following params:\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff0d5a99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "80/80 [==============================] - 16s 194ms/step - loss: 0.6443 - accuracy: 0.6198 - val_loss: 0.6257 - val_accuracy: 0.5964\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 15s 189ms/step - loss: 0.5111 - accuracy: 0.7610 - val_loss: 0.4639 - val_accuracy: 0.8147\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 16s 195ms/step - loss: 0.4334 - accuracy: 0.8193 - val_loss: 0.4274 - val_accuracy: 0.8046\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 15s 189ms/step - loss: 0.3838 - accuracy: 0.8369 - val_loss: 0.4016 - val_accuracy: 0.7995\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 15s 190ms/step - loss: 0.3390 - accuracy: 0.8657 - val_loss: 0.4612 - val_accuracy: 0.7817\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 16s 195ms/step - loss: 0.3044 - accuracy: 0.8833 - val_loss: 0.3330 - val_accuracy: 0.8503\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 15s 185ms/step - loss: 0.2797 - accuracy: 0.8934 - val_loss: 0.3133 - val_accuracy: 0.8604\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 15s 186ms/step - loss: 0.2485 - accuracy: 0.9084 - val_loss: 0.3017 - val_accuracy: 0.8629\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 15s 189ms/step - loss: 0.2175 - accuracy: 0.9203 - val_loss: 0.3983 - val_accuracy: 0.8173\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 15s 187ms/step - loss: 0.2000 - accuracy: 0.9279 - val_loss: 0.2940 - val_accuracy: 0.8706\n"
     ]
    }
   ],
   "source": [
    "# Training the Data\n",
    "history = model.fit(train_generator, \n",
    "                    batch_size=20,\n",
    "                    epochs=10, \n",
    "                    validation_data=validation_generator,\n",
    "                    validation_batch_size=20,\n",
    "                    shuffle=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0c46c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fc54fba",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3542e0",
   "metadata": {},
   "source": [
    "What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "- 0.40\n",
    "- 0.60\n",
    "- **0.90**\n",
    "- 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9b7ef65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8745294809341431"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = history.history.get(\"accuracy\")\n",
    "accuracy.sort()\n",
    "np.median(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b411fcd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced1081b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64f8cb90",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff80fcc2",
   "metadata": {},
   "source": [
    "What is the standard deviation of training loss for all the epochs for this model?\n",
    "\n",
    "- **0.11**\n",
    "- 0.66\n",
    "- 0.99\n",
    "- 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b3c88a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1333373644863049"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loss = history.history.get(\"loss\")\n",
    "np.array(training_loss).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7682a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1ec178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd47a23b",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f7db3",
   "metadata": {},
   "source": [
    "For the next two questions, we'll generate more data using data augmentations.\n",
    "\n",
    "Add the following augmentations to your training data generator:\n",
    "\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f76cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=20\n",
    "shuffle=True \n",
    "target_size=(150, 150)\n",
    "seed = 100\n",
    "color_mode=\"rgb\"\n",
    "class_mode='binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccd7f64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                     rotation_range=40,\n",
    "                                     width_shift_range=0.2,\n",
    "                                     height_shift_range=0.2,\n",
    "                                     shear_range=0.2,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip=True,\n",
    "                                     fill_mode='nearest'\n",
    "                                    ).flow_from_directory(train_path,\n",
    "                                                          target_size=target_size,\n",
    "                                                          color_mode=color_mode,\n",
    "                                                          classes=None, # or os.listdir(train_path)\n",
    "                                                          class_mode=class_mode,\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          shuffle=shuffle,\n",
    "                                                          seed=seed\n",
    "                                                         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "459fc483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 394 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                          rotation_range=40,\n",
    "                                          width_shift_range=0.2,\n",
    "                                          height_shift_range=0.2,\n",
    "                                          shear_range=0.2,\n",
    "                                          zoom_range=0.2,\n",
    "                                          horizontal_flip=True,\n",
    "                                          fill_mode='nearest'\n",
    "                                         ).flow_from_directory(validation_path,\n",
    "                                                               target_size=target_size,\n",
    "                                                               color_mode=color_mode,\n",
    "                                                               classes=None, # or os.listdir(train_path)\n",
    "                                                               class_mode=class_mode,\n",
    "                                                               batch_size=batch_size,\n",
    "                                                               shuffle=shuffle,\n",
    "                                                               seed=seed\n",
    "                                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ab296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7eb51ece",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7746782b",
   "metadata": {},
   "source": [
    "Let's train our model for 10 more epochs using the same code as previously. Make sure you don't re-create the model - we want to continue training the model we already started training.\n",
    "\n",
    "What is the mean of validation loss for all the epochs for the model trained with augmentations?\n",
    "\n",
    "- 0.15\n",
    "- 0.77\n",
    "- **0.37**\n",
    "- 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acebbed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "80/80 [==============================] - 33s 412ms/step - loss: 0.4493 - accuracy: 0.7905 - val_loss: 0.4984 - val_accuracy: 0.7462\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 33s 411ms/step - loss: 0.4291 - accuracy: 0.7986 - val_loss: 0.3667 - val_accuracy: 0.8452\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 33s 412ms/step - loss: 0.4303 - accuracy: 0.7986 - val_loss: 0.4114 - val_accuracy: 0.7893\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 33s 414ms/step - loss: 0.4133 - accuracy: 0.8137 - val_loss: 0.3757 - val_accuracy: 0.8376\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 33s 414ms/step - loss: 0.3807 - accuracy: 0.8306 - val_loss: 0.3567 - val_accuracy: 0.8477\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 33s 413ms/step - loss: 0.3839 - accuracy: 0.8306 - val_loss: 0.3918 - val_accuracy: 0.8299\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 33s 415ms/step - loss: 0.3695 - accuracy: 0.8444 - val_loss: 0.4147 - val_accuracy: 0.7893\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 33s 413ms/step - loss: 0.3679 - accuracy: 0.8407 - val_loss: 0.3860 - val_accuracy: 0.8325\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 33s 410ms/step - loss: 0.3502 - accuracy: 0.8425 - val_loss: 0.3434 - val_accuracy: 0.8604\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 33s 416ms/step - loss: 0.3554 - accuracy: 0.8469 - val_loss: 0.3372 - val_accuracy: 0.8553\n"
     ]
    }
   ],
   "source": [
    "# Training the Data\n",
    "history = model.fit(train_generator, \n",
    "                    batch_size=20,\n",
    "                    epochs=10, \n",
    "                    validation_data=validation_generator,\n",
    "                    validation_batch_size=10,\n",
    "                    shuffle=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cd5d733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38821635246276853"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_loss = history.history.get(\"val_loss\") \n",
    "np.array(validation_loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9fe7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227f522c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4742c8bb",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ef16f4",
   "metadata": {},
   "source": [
    "What's the average of validation accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?\n",
    "\n",
    "- **0.84**\n",
    "- 0.54\n",
    "- 0.44\n",
    "- 0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8fb607d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8335025310516357"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_accuracy = history.history.get(\"val_accuracy\")\n",
    "np.array(validation_accuracy[-5:]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df608ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a2f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
